{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.cluster.vq import kmeans, kmeans2\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data and pre-process it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             specs1\n",
      "count  43219.000000\n",
      "mean       0.064918\n",
      "std        0.029648\n",
      "min        0.017000\n",
      "25%        0.050000\n",
      "50%        0.059000\n",
      "75%        0.070000\n",
      "max        0.636000\n",
      "    make     model                      specs  specs1\n",
      "0  acura  acura-cl         1997 Acura CL 2.2    0.047\n",
      "1  acura  acura-cl         1998 Acura CL 2.3    0.049\n",
      "2  acura  acura-cl  1998 Acura CL 2.3 Premium   0.049\n",
      "3  acura  acura-cl         1999 Acura CL 2.3    0.049\n",
      "4  acura  acura-cl         1997 Acura CL 3.0    0.062\n"
     ]
    }
   ],
   "source": [
    "FILEPATH = os.path.abspath(\"../data/2023-03-25_22hr_29min_ptwr_data.tsv\")\n",
    "df = pd.read_csv(FILEPATH, sep=\"\\t\")\n",
    "\n",
    "MAKE = \"make\"\n",
    "MODEL = \"model\"\n",
    "SPECS = \"specs\"\n",
    "\n",
    "CLEAN_MAKE = re.compile(r\"((/make/)|(\\-power\\-to\\-weight\\-ratio\\-stats))\")\n",
    "CLEAN_MODEL = re.compile(r\"(/model/)\")\n",
    "CLEAN_SPECS = re.compile(r\"(\\\\t|\\\\n)\")\n",
    "\n",
    "df[MAKE] = df[MAKE].apply(lambda x: CLEAN_MAKE.sub(\"\", x))\n",
    "df[MODEL] = df[MODEL].apply(lambda x: CLEAN_MODEL.sub(\"\", x))\n",
    "df[SPECS] = df[SPECS].apply(lambda x: CLEAN_SPECS.sub(\"\", x))\n",
    "\n",
    "SEPARATOR = \":\"\n",
    "SPECS1 = \"specs1\"\n",
    "df[SPECS1] = df[SPECS].apply(lambda x: float(x.split(SEPARATOR)[-1]))\n",
    "df[SPECS] = df[SPECS].apply(lambda x: SEPARATOR.join((x.split(SEPARATOR)[:-1])))\n",
    "\n",
    "print(df.describe())\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to explore some models for this data. I will use discriminators for classifying high power-to-weight or low power-to-weight based upon mean, median and some clustering algorithms. I will first explore the discriminants and then start analysing classification models based upon each of those techniques."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt 1: Mean"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a discriminant based upon being above or below the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06491797589023347\n"
     ]
    }
   ],
   "source": [
    "mean = np.mean(df[SPECS1])\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attemp 2: Median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a discriminant based upon being above or below the median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.059\n"
     ]
    }
   ],
   "source": [
    "median = np.median(df[SPECS1])\n",
    "print(median)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt 3: Clustering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means Clustering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering with k=2 because we want 'high power to weight ratio' vs 'low power to weight ratio', just those two.\n",
    "Create a discriminant based upon which centroid a datum is closer to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scipy kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10053996 0.05440708]\n"
     ]
    }
   ],
   "source": [
    "kmeans_centroids, distortion = kmeans(df[SPECS1], K)\n",
    "print(kmeans_centroids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scipy kmeans2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05848388 0.13564123]\n"
     ]
    }
   ],
   "source": [
    "kmeans2_centroids, distortion2 = kmeans2(df[SPECS1], K)\n",
    "print(kmeans2_centroids)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.05921039]\n",
      " [0.14489163]]\n"
     ]
    }
   ],
   "source": [
    "X = df[SPECS1].to_numpy().reshape(-1,1)\n",
    "cf = KMeans(n_clusters=K, n_init='auto').fit(X)\n",
    "sklearn_centroids = cf.cluster_centers_\n",
    "print(sklearn_centroids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion: Attempts 1-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't think there is a lot of preprocessing to be done here, but now that I have some models I can start to classify the data and compare the results. A classification of '1' means 'high power-to-weight ratio' and a classification of '0' means 'low power-to-weight ratio'. An assumption here is that inferring the training data produces the ground truth labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIGH = 1\n",
    "LOW = 0\n",
    "\n",
    "NUM_FOLDS = 7\n",
    "LENGTH = len(df)\n",
    "\n",
    "df = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt 1 Classification: Mean Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_inference(df, mean):\n",
    "    result = df.apply(lambda x: HIGH if x > mean else LOW)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 0.9794298671849693, 0.9808875931324911, 0.9808875931324911, 1.0, 1.0]\n",
      "0.9916007219214216\n",
      "0.009709078600371913\n"
     ]
    }
   ],
   "source": [
    "mean_reference = mean_inference(df[SPECS1], mean)\n",
    "\n",
    "metrics = {}\n",
    "for i in range(NUM_FOLDS):\n",
    "    test = df.iloc[int(np.floor(LENGTH/NUM_FOLDS)*i):int(np.floor(LENGTH/NUM_FOLDS)*(i+1))]\n",
    "    train_values = df.iloc[~test.index.values][SPECS1]\n",
    "\n",
    "    mean = np.mean(train_values)\n",
    "    test_inferred = mean_inference(test[SPECS1], mean)\n",
    "    mean_reference_test_view = mean_reference.iloc[int(np.floor(LENGTH/NUM_FOLDS)*i):int(np.floor(LENGTH/NUM_FOLDS)*(i+1))]\n",
    "\n",
    "    # positive class is HIGH\n",
    "    tp = np.sum([True for x,y in zip(test_inferred,mean_reference_test_view) if x == y and x == HIGH])\n",
    "    tn = np.sum([True for x,y in zip(test_inferred,mean_reference_test_view) if x == y and x == LOW])\n",
    "    fp = np.sum([True for x,y in zip(test_inferred,mean_reference_test_view) if x != y and x == HIGH])\n",
    "    fn = np.sum([True for x,y in zip(test_inferred,mean_reference_test_view) if x != y and x == LOW])\n",
    "\n",
    "    metrics[str(i)] = [tp, tn, fp, fn]\n",
    "\n",
    "accuracies = []\n",
    "for key, val in metrics.items():\n",
    "    accuracies.append((val[0]+val[1])/np.sum(val))\n",
    "mean_accuracy_overall = np.mean(accuracies)\n",
    "mean_std_overall = np.std(accuracies)\n",
    "print(accuracies)\n",
    "print(mean_accuracy_overall)\n",
    "print(mean_std_overall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt 2 Classification: Median Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_inference(df, median):\n",
    "    result = df.apply(lambda x: HIGH if x > median else LOW)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9726271460965339, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9682539682539683]\n",
      "0.9915544449072147\n",
      "0.01340464661794367\n"
     ]
    }
   ],
   "source": [
    "median_reference = mean_inference(df[SPECS1], median)\n",
    "\n",
    "metrics = {}\n",
    "for i in range(NUM_FOLDS):\n",
    "    test = df.iloc[int(np.floor(LENGTH/NUM_FOLDS)*i):int(np.floor(LENGTH/NUM_FOLDS)*(i+1))]\n",
    "    train_values = df.iloc[~test.index.values][SPECS1]\n",
    "\n",
    "    median = np.median(train_values)\n",
    "    test_inferred = mean_inference(test[SPECS1], median)\n",
    "    median_reference_test_view = median_reference.iloc[int(np.floor(LENGTH/NUM_FOLDS)*i):int(np.floor(LENGTH/NUM_FOLDS)*(i+1))]\n",
    "\n",
    "    # positive class is HIGH\n",
    "    tp = np.sum([True for x,y in zip(test_inferred,median_reference_test_view) if x == y and x == HIGH])\n",
    "    tn = np.sum([True for x,y in zip(test_inferred,median_reference_test_view) if x == y and x == LOW])\n",
    "    fp = np.sum([True for x,y in zip(test_inferred,median_reference_test_view) if x != y and x == HIGH])\n",
    "    fn = np.sum([True for x,y in zip(test_inferred,median_reference_test_view) if x != y and x == LOW])\n",
    "\n",
    "    metrics[str(i)] = [tp, tn, fp, fn]\n",
    "\n",
    "accuracies = []\n",
    "for key, val in metrics.items():\n",
    "    accuracies.append((val[0]+val[1])/np.sum(val))\n",
    "median_accuracy_overall = np.mean(accuracies)\n",
    "median_std_overall = np.std(accuracies)\n",
    "print(accuracies)\n",
    "print(median_accuracy_overall)\n",
    "print(median_std_overall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt 3 Classification: K-Means Clustering Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_inference(df, high_centroid, low_centroid):\n",
    "    result = df.apply(lambda x: HIGH if np.abs(high_centroid-x) < np.abs(low_centroid-x) else LOW)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scipy kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9606413994169096, 1.0, 0.9922254616132167, 0.9748947197926789, 1.0, 0.9919015225137674, 0.9935212180110139]\n",
      "0.9875977601925124\n",
      "0.013473089948028816\n"
     ]
    }
   ],
   "source": [
    "high_kmeans_centroid = kmeans_centroids[1] if kmeans_centroids[1] > kmeans_centroids[0] else kmeans_centroids[0]\n",
    "low_kmeans_centroid = kmeans_centroids[1] if kmeans_centroids[1] < kmeans_centroids[0] else kmeans_centroids[0]\n",
    "kmeans_reference = kmeans_inference(df[SPECS1], high_kmeans_centroid, low_kmeans_centroid)\n",
    "\n",
    "metrics = {}\n",
    "for i in range(NUM_FOLDS):\n",
    "    test = df.iloc[int(np.floor(LENGTH/NUM_FOLDS)*i):int(np.floor(LENGTH/NUM_FOLDS)*(i+1))]\n",
    "    train_values = df.iloc[~test.index.values][SPECS1]\n",
    "\n",
    "    centroids, distortion = kmeans(train_values, K)\n",
    "    high_centroid = centroids[1] if centroids[1] > centroids[0] else centroids[0]\n",
    "    low_centroid = centroids[1] if centroids[1] < centroids[0] else centroids[0]\n",
    "    test_inferred = kmeans_inference(test[SPECS1], high_centroid, low_centroid)\n",
    "    kmeans_reference_test_view = kmeans_reference.iloc[int(np.floor(LENGTH/NUM_FOLDS)*i):int(np.floor(LENGTH/NUM_FOLDS)*(i+1))]\n",
    "\n",
    "    # positive class is HIGH\n",
    "    tp = np.sum([True for x,y in zip(test_inferred,kmeans_reference_test_view) if x == y and x == HIGH])\n",
    "    tn = np.sum([True for x,y in zip(test_inferred,kmeans_reference_test_view) if x == y and x == LOW])\n",
    "    fp = np.sum([True for x,y in zip(test_inferred,kmeans_reference_test_view) if x != y and x == HIGH])\n",
    "    fn = np.sum([True for x,y in zip(test_inferred,kmeans_reference_test_view) if x != y and x == LOW])\n",
    "\n",
    "    metrics[str(i)] = [tp, tn, fp, fn]\n",
    "\n",
    "accuracies = []\n",
    "for key, val in metrics.items():\n",
    "    accuracies.append((val[0]+val[1])/np.sum(val))\n",
    "kmeans_accuracy_overall = np.mean(accuracies)\n",
    "kmeans_std_overall = np.std(accuracies)\n",
    "print(accuracies)\n",
    "print(kmeans_accuracy_overall)\n",
    "print(kmeans_std_overall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scipy kmeans2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9787819889860706, 0.9909297052154195, 1.0, 0.9862325882734047, 0.9933592484612893, 0.981859410430839, 0.9982183349530288]\n",
      "0.9899116109028645\n",
      "0.007425261936167088\n"
     ]
    }
   ],
   "source": [
    "high_kmeans2_centroid = kmeans2_centroids[1] if kmeans2_centroids[1] > kmeans2_centroids[0] else kmeans2_centroids[0]\n",
    "low_kmeans2_centroid = kmeans2_centroids[1] if kmeans2_centroids[1] < kmeans2_centroids[0] else kmeans2_centroids[0]\n",
    "kmeans2_reference = kmeans_inference(df[SPECS1], high_kmeans2_centroid, low_kmeans2_centroid)\n",
    "\n",
    "metrics = {}\n",
    "for i in range(NUM_FOLDS):\n",
    "    test = df.iloc[int(np.floor(LENGTH/NUM_FOLDS)*i):int(np.floor(LENGTH/NUM_FOLDS)*(i+1))]\n",
    "    train_values = df.iloc[~test.index.values][SPECS1]\n",
    "\n",
    "    centroids, distortion = kmeans2(train_values, K)\n",
    "    high_centroid = centroids[1] if centroids[1] > centroids[0] else centroids[0]\n",
    "    low_centroid = centroids[1] if centroids[1] < centroids[0] else centroids[0]\n",
    "    test_inferred = kmeans_inference(test[SPECS1], high_centroid, low_centroid)\n",
    "    kmeans2_reference_test_view = kmeans2_reference.iloc[int(np.floor(LENGTH/NUM_FOLDS)*i):int(np.floor(LENGTH/NUM_FOLDS)*(i+1))]\n",
    "\n",
    "    # positive class is HIGH\n",
    "    tp = np.sum([True for x,y in zip(test_inferred,kmeans2_reference_test_view) if x == y and x == HIGH])\n",
    "    tn = np.sum([True for x,y in zip(test_inferred,kmeans2_reference_test_view) if x == y and x == LOW])\n",
    "    fp = np.sum([True for x,y in zip(test_inferred,kmeans2_reference_test_view) if x != y and x == HIGH])\n",
    "    fn = np.sum([True for x,y in zip(test_inferred,kmeans2_reference_test_view) if x != y and x == LOW])\n",
    "\n",
    "    metrics[str(i)] = [tp, tn, fp, fn]\n",
    "\n",
    "accuracies = []\n",
    "for key, val in metrics.items():\n",
    "    accuracies.append((val[0]+val[1])/np.sum(val))\n",
    "kmeans2_accuracy_overall = np.mean(accuracies)\n",
    "kmeans2_std_overall = np.std(accuracies)\n",
    "print(accuracies)\n",
    "print(kmeans2_accuracy_overall)\n",
    "print(kmeans2_std_overall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9909297052154195, 0.9836410754778102, 0.9872044055717525, 0.9912536443148688, 0.9825072886297376, 0.9761904761904762, 0.00923226433430515]\n",
      "0.8458512656763386\n",
      "0.34158263568063074\n"
     ]
    }
   ],
   "source": [
    "sklearn_reference = cf.predict(df[SPECS1].to_numpy().reshape(-1,1))\n",
    "\n",
    "metrics = {}\n",
    "for i in range(NUM_FOLDS):\n",
    "    test = df.iloc[int(np.floor(LENGTH/NUM_FOLDS)*i):int(np.floor(LENGTH/NUM_FOLDS)*(i+1))]\n",
    "    train_values = df.iloc[~test.index.values][SPECS1]\n",
    "\n",
    "    train_values = train_values.to_numpy().reshape(-1,1)\n",
    "    sklearn_cf = KMeans(n_clusters=K, n_init='auto').fit(train_values)\n",
    "    test_inferred = sklearn_cf.predict(test[SPECS1].to_numpy().reshape(-1,1))\n",
    "    sklearn_reference_test_view = sklearn_reference[int(np.floor(LENGTH/NUM_FOLDS)*i):int(np.floor(LENGTH/NUM_FOLDS)*(i+1))]\n",
    "\n",
    "    # positive class is HIGH\n",
    "    tp = np.sum([True for x,y in zip(test_inferred,sklearn_reference_test_view) if x == y and x == HIGH])\n",
    "    tn = np.sum([True for x,y in zip(test_inferred,sklearn_reference_test_view) if x == y and x == LOW])\n",
    "    fp = np.sum([True for x,y in zip(test_inferred,sklearn_reference_test_view) if x != y and x == HIGH])\n",
    "    fn = np.sum([True for x,y in zip(test_inferred,sklearn_reference_test_view) if x != y and x == LOW])\n",
    "\n",
    "    metrics[str(i)] = [tp, tn, fp, fn]\n",
    "\n",
    "accuracies = []\n",
    "for key, val in metrics.items():\n",
    "    accuracies.append((val[0]+val[1])/np.sum(val))\n",
    "sklearn_accuracy_overall = np.mean(accuracies)\n",
    "sklearn_std_overall = np.std(accuracies)\n",
    "print(accuracies)\n",
    "print(sklearn_accuracy_overall)\n",
    "print(sklearn_std_overall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion: Classification Attempts 1-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a 70/30 train/test split for k-fold cross validation and averaging the accuracies, I would argue that the mean or kmeans2 discriminators work best because of the low standard deviations along with the high accuracies. They had some of the best consistency as well as high accuracies which implies they may generalize well. I chose accuracy as the fitness metric because of the general nature of the problem. We want to maximize correct classifications and don't need to dig deeper into precision or recall, etc, which tends to be dictated by the application. Again, this application is fairly straightforward, classify the power-to-weight ratios as either 'high' or 'low' and we want to get that right as much as possible -- no further details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer for Objective 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this data, a high power-to-weight ratio is either anything above the mean and a low power-to-weight ratio is anything below the mean, such that the mean is 0.0649.\n",
    "Or, a high power-to-weight ratio is closer to the value 0.13564123 than the value 0.05848388, and vice-versa for a low power-to-weight ratio."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
